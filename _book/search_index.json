[["index.html", "1 Welcome to S2Y Lab 8 1.1 Introduction", " S2Y Lab 8 Comparing regression lines 1 Welcome to S2Y Lab 8 Intended Learning Outcomes: use R to carry out an ANCOVA; use R output for model selection when comparing regression lines; and interpret confidence intervals for model selection when comparing regression lines. 1.1 Introduction In Chapter 4 of the lectures we looked at how to select the best linear model in the case where we have two explanatory variables, one of which is a grouping variable (factor). Three models were considered: (i) different regression lines for each group; (ii) parallel regression lines; and (iii) a single regression line. Selection was based on the calculation and interpretation of confidence intervals. Here is a reminder of some of the formulae: Model 1: Two different regression lines \\[\\mathbb{E}(Y_{ij}) = \\alpha_i+\\beta_i(x_{ij}-\\bar{x}_{i.}), \\quad i=1,2, \\quad j=1,\\ldots,n_i\\] The least squares estimates of the parameters are \\[\\hat{\\boldsymbol \\beta} = \\begin{bmatrix} \\hat{\\alpha}_1 \\\\[0.3em] \\hat{\\beta}_1 \\\\[0.3em] \\hat{\\alpha}_2 \\\\[0.3em] \\hat{\\beta}_2\\end{bmatrix} = \\begin{bmatrix} \\bar{y}_{1.} \\\\[0.3em] \\frac{S_{x_1 y_1}}{S_{x_1 x_1}} \\\\[0.3em] \\bar{y}_{2.} \\\\[0.3em] \\frac{S_{x_2 y_2}}{S_{x_2 x_2}}\\end{bmatrix}\\] and the residual sum of squares can be written as \\[\\text{RSS} = \\text{RSS}_1 + \\text{RSS}_2,\\] where \\[\\text{RSS}_1 = S_{y_1 y_1} - \\frac{\\left(S_{x_1 y_1}\\right)^2}{S_{x_1 x_1}} \\quad\\quad \\text{and} \\quad\\quad \\text{RSS}_2 = S_{y_2 y_2} - \\frac{\\left(S_{x_2 y_2}\\right)^2}{S_{x_2 x_2}}.\\] The equations for the parameters are identical to those which are found when a separate straight line is fitted individually to the two groups, with \\(\\text{RSS}_1\\) and \\(\\text{RSS}_2\\) the residual sums of squares from fitting individual regression lines to each group. Recall that in order to determine if a model with parallel lines is adequate, we need to construct a 95% confidence interval for \\((\\beta_1 - \\beta_2)\\) using the standard formula: \\[\\mathbf{b}^\\top\\boldsymbol{\\hat{\\beta}} \\pm t(n-p; 0.975)\\sqrt{\\frac{\\text{RSS}}{n-p}\\mathbf{b}^\\top(\\mathbf{X}^\\top\\mathbf{X})^{-1}\\mathbf{b}},\\] That is, \\[(\\hat{\\beta}_1-\\hat{\\beta}_2) \\pm t(n_1+n_2-4; 0.975)\\sqrt{\\left(\\frac{\\text{RSS}_1+\\text{RSS}_2}{n_1+n_2-4}\\right)\\left(\\frac{1}{S_{x_1x_1}}+\\frac{1}{S_{x_2x_2}}\\right)}.\\] If the confidence interval for \\(\\beta_1 - \\beta_2\\) includes 0, there is insufficient evidence of a difference in the slopes. We will go on to fit the parallel lines model. Model 2: Two parallel regression lines \\[\\mathbb{E}(Y_{ij}) = \\alpha_i+\\beta(x_{ij}-\\bar{x}_{i.}), \\quad i=1,2, \\quad j=1,\\ldots,n_i\\] Here the least squares estimates of the parameters are \\[\\hat{\\boldsymbol \\beta} = \\begin{bmatrix} \\hat{\\alpha}_1 \\\\[0.3em] \\hat{\\alpha}_2 \\\\[0.3em] \\hat{\\beta}\\end{bmatrix} = \\begin{bmatrix} \\bar{y}_{1.} \\\\[0.3em] \\bar{y}_{2.} \\\\[0.3em] \\frac{S_{x_1 y_1} + S_{x_2 y_2}}{S_{x_1 x_1} + S_{x_2 x_2}}\\end{bmatrix}\\] and the residual sum of squares is given as \\[\\text{RSS} = S_{y_1 y_1} + S_{y_2 y_2} - \\frac{\\left(S_{x_1 y_1} + S_{x_2 y_2}\\right)^2}{S_{x_1 x_1} + S_{x_2 x_2}}.\\] By constructing a confidence interval for the difference between the regression lines, \\(\\alpha_1 - \\alpha_2 + \\beta \\left(\\bar{x}_{2.} - \\bar{x}_{1.}\\right)\\), and examining whether this interval includes 0, we can assess whether a single straight line, with no difference between the groups, is adequate for the data. The 95% confidence interval has the form \\[\\mathbf{b}^\\top\\boldsymbol{\\hat{\\beta}} \\pm t(n_1 + n_2 - 3; 0.975)\\sqrt{\\frac{\\text{RSS}}{n_1 + n_2 - 3}\\mathbf{b}^\\top(\\mathbf{X}^\\top\\mathbf{X})^{-1}\\mathbf{b}},\\] with \\(\\mathbf{b}^\\top = \\begin{bmatrix} 1 &amp; -1 &amp; \\left(\\bar{x}_{2.} - \\bar{x}_{1.}\\right) \\end{bmatrix}\\). That is, \\[\\hat{\\alpha}_1-\\hat{\\alpha}_2+\\hat{\\beta}(\\bar{x}_{2.}-\\bar{x}_{1.}) \\pm t(n_1 + n_2 - 3,0.975) \\sqrt{\\left(\\frac{\\text{RSS}}{n_1 + n_2 - 3}\\right)\\left(\\frac{1}{n_1}+\\frac{1}{n_2}+\\frac{(\\bar{x}_{2.}-\\bar{x}_{1.})^2}{S_{x_1x_1}+S_{x_2x_2}}\\right)}.\\] If the confidence interval includes 0, there is insufficient evidence of a difference between the regression lines. We will then go on to fit a single regression line. Model 3: Single regression line \\[\\mathbb{E}(Y_{ij}) = \\alpha + \\beta(x_{ij}-\\bar{x}_{i.}), \\quad i=1,2, \\quad j=1,\\ldots,n_i\\] The parameter estimates are then \\[\\hat{\\boldsymbol \\beta} = \\begin{bmatrix} \\hat{\\alpha} \\\\[0.3em] \\hat{\\beta}\\end{bmatrix} = \\begin{bmatrix} \\bar{y}_{..} \\\\[0.3em] \\frac{S_{x y}}{S_{x x}}\\end{bmatrix}\\] In this lab the main focus will be on how to perform an analysis of covariance (ANCOVA) in R. However, we will also consider the interpretation of the above confidence intervals. Performing ANCOVA in R will provide \\(p\\)-values, which allow us to compare the three models of interest. "],["example-1-cholesterol-levels-in-iowa-and-nebraska.html", "2 Example 1: Cholesterol levels in Iowa and Nebraska 2.1 Exploratory analysis 2.2 Statistical analysis 2.3 Confidence intervals", " 2 Example 1: Cholesterol levels in Iowa and Nebraska In a survey to examine relationships between the nutrition and the health of women in the Mid-West of the USA, the concentration of cholesterol (mg/dL) in blood serum was measured on randomly selected subjects in Iowa and Nebraska. Cholesterol is known to depend on age for these subjects. Interest lies in whether there are any differences between the measurements in Iowa and those in Nebraska. Read in the data using: cholest &lt;- read.csv(&quot;cholest2.csv&quot;) The dataset contains four columns:    C1: Age    C2: Cholesterol level    C3: State (1 = Iowa, 2 = Nebraska)    C4: State name Question of interest: Are there any differences between the cholesterol measurements in Iowa and those in Nebraska? 2.1 Exploratory analysis Produce a plot of cholesterol against age, labelled by state, using the commands: plot(Cholesterol ~ Age, pch = State, data = cholest, col = State, xlab = &quot;Age (years)&quot;, ylab = &quot;Cholesterol (mg/dl)&quot;, cex = 1.5) legend(&quot;topleft&quot;, legend = c(&quot;Iowa&quot;, &quot;Nebraska&quot;), pch = 1:2, horiz = TRUE, bty = &quot;n&quot;, cex = 1.2, col = 1:2) Figure 2.1: Scatterplot of cholesterol level against age. COMMENT: What can you conclude from Figure 2.1? Do you think that the relationship between cholesterol and age is completely different in each state? Do you think either a parallel or single line relationship may be appropriate? 2.2 Statistical analysis Initially, a model can be fitted in R that allows the relationship between age and cholesterol to be completely different for each state. This can be done by using the command: Model1 &lt;- lm(Cholesterol ~ Age * statename, data = cholest) This fits a linear regression model between cholesterol and age where the relationship is allowed to change depending on state. Therefore, the model contains a covariate of age, a factor of state name and the interaction between state name and age. If the model with two completely separate regression lines is appropriate then we say that there is an interaction (and the interaction term would be statistically significant). An interaction would tell us that the relationship between cholesterol and age is different depending on whether the population of interest is Iowa or Nebraska. In order to assess this, the output of most interest to us here is in the analysis of variance table obtained using: anova(Model1) ## Analysis of Variance Table ## ## Response: Cholesterol ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Age 1 48976 48976 26.3124 2.388e-05 *** ## statename 1 5456 5456 2.9315 0.09877 . ## Age:statename 1 709 709 0.3809 0.54247 ## Residuals 26 48395 1861 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 QUESTION: Based on the ANOVA table, what can we say about the significance of the interaction term? The \\(p\\)-value for Age is 2.388e-05, and thus the interaction term is statistically significant. The \\(p\\)-value for statename is 0.09877, and thus the interaction term is statistically insignificant. The \\(p\\)-value for Age:statename is 0.54247, and thus the interaction term is statistically insignificant. What does the significance of the interaction term tell us about the model selection? We should choose different regression lines We should fit parallel regression lines and test if this is appropriate. We should fit a single regression line and test if this is appropriate. Since the interaction term is not statistically significant (0.542) we then fit a model which assumes parallel lines: Model2 &lt;- lm(Cholesterol ~ Age + statename, data = cholest) anova(Model2) ## Analysis of Variance Table ## ## Response: Cholesterol ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Age 1 48976 48976 26.9298 1.831e-05 *** ## statename 1 5456 5456 3.0003 0.09466 . ## Residuals 27 49104 1819 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 QUESTION: Which of the following interpretations is appropriate about the ANOVA table? The \\(p\\)-value for Age is statistically significant, and hence the current model is appropriate. The \\(p\\)-value for Age is statistically insignificant, and hence we should fit a single regression line and check if this model is appropriate. The \\(p\\)-value for statename is statistically significant, and hence the current model is appropriate. The \\(p\\)-value for statename is statistically insignificant, and hence we should fit a single regression line and check if this model is appropriate. Since the \\(p\\)-value for the factor statename is not statistically significant (0.095), a single regression line may be appropriate for the data. QUESTION: Fit a single regression line to this dataset and comment on its appropriateness. Hint This is simply the simple linear regression model we learned about in previous weeks. Fit using lm and Cholesterol as the response variable and Age as the predictor variable. Solution Model3 &lt;- lm(Cholesterol ~ Age, data = cholest) anova(Model3) ## Analysis of Variance Table ## ## Response: Cholesterol ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Age 1 48976 48976 25.134 2.673e-05 *** ## Residuals 28 54560 1949 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Since the \\(p\\)-value for Age is 2.673e-05, which is much smaller than 0.05, we can conclude that Age is useful in predicting cholesterol level and hence a single regression line is appropriate. The final model (Model3) regression line can be superimposed onto Figure 2.1 using abline(Model3) plot(Cholesterol ~ Age, pch = State, data = cholest, col = State, xlab = &quot;Age (years)&quot;, ylab = &quot;Cholesterol (mg/dl)&quot;, cex = 1.5) legend(&quot;topleft&quot;, legend = c(&quot;Iowa&quot;, &quot;Nebraska&quot;), pch = 1:2, horiz = TRUE, bty = &quot;n&quot;, cex = 1.2, col = 1:2) abline(Model3) Figure 2.2: Scatterplot of cholesterol level against age. Figure 2.2 shows the fitted regression line from Model3 superimposed onto the scatterplot of cholesterol level and age. While skipped here, the assumptions of this simple linear regression model should be checked. The above analysis could also be performed by computing confidence intervals to investigate differences between the regression lines. 2.3 Confidence intervals Confidence intervals can be used to compare the models. To compare the full model with completely separate lines to the parallel lines model, we compute a confidence interval that compares the slopes. The 95% confidence interval for \\(\\left(\\beta_1 - \\beta_2\\right)\\) is \\[(\\hat{\\beta}_1-\\hat{\\beta}_2) \\pm t(n_1+n_2-4; 0.975)\\sqrt{\\left(\\frac{\\text{RSS}_1+\\text{RSS}_2}{n_1+n_2-4}\\right)\\left(\\frac{1}{S_{x_1x_1}}+\\frac{1}{S_{x_2x_2}}\\right)}\\] To compute the 95% confidence interval we first need to obtain its components. We can obtain \\(\\hat{\\beta}_1\\) and \\(\\hat{\\beta}_2\\) from coef(Model1) ## (Intercept) Age statenameNebraska ## 35.8112138 3.2381449 65.4865523 ## Age:statenameNebraska ## -0.7177069 which gives us the model estimates of the coefficients. Here, Iowa is taken as the ‘reference’ state (due to being coded as 1, while Nebraska is 2), and so its slope parameter, \\(\\hat{\\beta}_1\\), is given by beta1 &lt;- coef(Model1)[2] The number in the square brackets picks out the element of interest. The slope for Nebraska (\\(\\hat{\\beta}_2\\)) is found by adding together the coefficients of age and its state interaction, such that beta2 &lt;- coef(Model1)[2] + coef(Model1)[4] The \\(t\\)-value can be obtained using the commands n1 &lt;- sum(cholest$State == 1) n2 &lt;- sum(cholest$State == 2) p &lt;- 4 t.val &lt;- qt(p = 0.975, df = (n1 + n2 - p)) The residual sum of squares, \\(\\text{RSS} = \\text{RSS}_1 + \\text{RSS}_2\\), can be found from the analysis of variance table using the following command RSS &lt;- anova(Model1)[4, 2] Now, we just need to find the sum of squares, \\(S_{x_1 x_1}\\) and \\(S_{x_2 x_2}\\), for each state, which can be done using x1 &lt;- cholest[cholest$State == 1, 1] x2 &lt;- cholest[cholest$State == 2, 1] xbar1 &lt;- mean(x1) xbar2 &lt;- mean(x2) Sx1x1 &lt;- sum((x1 - xbar1)^2) Sx2x2 &lt;- sum((x2 - xbar2)^2) ese &lt;- sqrt(((RSS)/(n1+n2-p)) * ((1/Sx1x1)+(1/Sx2x2))) We can now obtain the 95% confidence interval for the difference in slopes using the following commands lower &lt;- (beta1-beta2) - t.val * ese upper &lt;- (beta1-beta2) + t.val * ese int &lt;- c(lower, upper) COMMENT: The 95% confidence interval for the difference in slopes is (-1.67, 3.11). What does this tell us about fitting different regression lines for the two states? Does it tell us anything about potential differences between the two states? To compare the parallel lines model and the single regression line model, we compute a 95% confidence interval for the difference between parallel regression lines: \\[ \\hat{\\alpha}_1-\\hat{\\alpha}_2+\\hat{\\beta}(\\bar{x}_{2.}-\\bar{x}_{1.}) \\pm t(n_1 + n_2 - 3,0.975) \\sqrt{\\left(\\frac{\\text{RSS}}{n_1 + n_2 - 3}\\right)\\left(\\frac{1}{n_1}+\\frac{1}{n_2}+\\frac{(\\bar{x}_{2.}-\\bar{x}_{1.})^2}{S_{x_1x_1}+S_{x_2x_2}}\\right)}\\] We need to be careful not to compute the confidence interval in a similar way to the previous one, with just using the coefficient estimates from Model2. This is because the least squares estimates of parameters, given in Introduction (Section 1.1), are derived after reparameterising the model by mean centering age. However, we did not reparameterise Model2, and therefore, the estimates of intercepts, \\(\\hat{\\alpha}_1\\) and \\(\\hat{\\alpha}_2\\), will be different from the formula. One way of reparameterising Model2 can be done by using the following commands: Y &lt;- cholest$Cholesterol Age &lt;- cholest$Age Age[cholest$State == 1] &lt;- Age[cholest$State == 1] - xbar1 Age[cholest$State == 2] &lt;- Age[cholest$State == 2] - xbar2 Model2 &lt;- lm(Y ~ Age + cholest$statename) Here Age is our reparameterised age variable, where we have subtracted from age the corresponding state means. We can now obtain the 95% confidence interval for the difference between parallel regression lines using the following commands: alpha1 &lt;- coef(Model2)[1] alpha2 &lt;- coef(Model2)[1] + coef(Model2)[3] beta &lt;- coef(Model2)[2] p &lt;- 3 t.val &lt;- qt(p = 0.975, df = (n1 + n2 - p)) RSS &lt;- anova(Model2)[3, 2] ese &lt;- sqrt((RSS/(n1+n2-p))*((1/n1)+(1/n2)+((xbar2-xbar1)^2/(Sx1x1+Sx2x2)))) lower &lt;- alpha1-alpha2+(beta*(xbar2-xbar1)) - t.val * ese upper &lt;- alpha1-alpha2+(beta*(xbar2-xbar1)) + t.val * ese int &lt;- c(lower, upper) COMMENT: The 95% confidence interval for the difference between parallel lines is (-62.59, 5.29). What does this tell us about fitting parallel lines for the two states? "],["example-2-respiratory-distress-syndrome.html", "3 Example 2: Respiratory Distress Syndrome", " 3 Example 2: Respiratory Distress Syndrome We have seen this example in Lecture 15. To recap, premature babies often suffer from a variety of problems and respiratory distress syndrome (RDS) is a major one of these problems. It is thought that the occurrence of this syndrome might be related to a property of the blood called red cell deformability. This refers to the ability of red cells to change shape to pass through small pores. The rate (Lrate, on a log scale) of blood flow through a set of 3\\(\\mu\\)m pores has been recorded for two groups of babies, some of whom suffer from respiratory distress syndrome (RDS = 2) and some who do not (RDS = 1). The gestational age (GA) in weeks of each baby is also recorded. These data were kindly provided by Queen Mother’s Hospital, Glasgow. Read in the data using: rds &lt;- read.csv(&quot;respiratory.csv&quot;) The dataset contains three columns:    C1: Lrate    C2: GA    C3: RDS (1 = does not suffer from RDS, 2 = suffers from RDS) Use what you have learned from Example 1 to answer the following question of interest. Question of interest: Are there any differences between the rate of blood flow measurements for babies that do, and do not, suffer from RDS, after correcting for the gestational age? TASK: Produce a scatterplot to explore the relationship between Lrate and GA, labelled by RDS. Do you think this relationship differs by RDS? Which model do you think is most appropriate to describe the data? plot(Lrate ~ GA, pch = RDS, data = rds, ylab = &quot;LRate (log rate of blood flow)&quot;, xlab = &quot;Gestational age (Weeks)&quot;) legend(&quot;topleft&quot;, legend = c(&quot;No RDS&quot;, &quot;RDS&quot;), pch = 1:2, bty = &quot;n&quot;, cex = 1.2) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
